{
  "personal": {
    "name": "Andreas Hailu",
    "title": "Software Engineer",
    "description": "I'm a software engineer specializing in distributed systems and enterprise applications",
    "profileImage": "/profile.jpg?height=400&width=400",
    "resumeUrl": "https://drive.google.com/file/d/1gxodq48W6zjCQcTReIB3eC_YPBMNR8ER/view?usp=drive_link"
  },
  "skills": [
    {
      "name": "Java",
      "category": "language",
      "color": "primary"
    },
    {
      "name": "Python",
      "category": "language",
      "color": "secondary"
    },
    {
      "name": "C#",
      "category": "language",
      "color": "accent"
    },
    {
      "name": "C++",
      "category": "language",
      "color": "highlight"
    },
    {
      "name": "TypeScript",
      "category": "language",
      "color": "primary"
    },
    {
      "name": "AWS",
      "category": "cloud",
      "color": "secondary"
    },
    {
      "name": "Azure",
      "category": "cloud",
      "color": "accent"
    }
  ],
  "experience": [
    {
      "id": "current",
      "title": "Senior Software Engineer",
      "company": "Microsoft",
      "period": "2024 - Present",
      "isCurrent": true,
      "description": "Building an enterprise grade cutting-edge information retrieval & search engine on Azure empowered with AI üîé",
      "technologies": ["C#", "Python", "Azure", "Artificial Intelligence"],
      "side": "left"
    },
    {
      "id": "2023",
      "title": "Vice President Software Engineer/Tech Lead",
      "company": "Goldman Sachs",
      "period": "2023 - 2024",
      "isCurrent": false,
      "description": "Core Data Engineering - event management & data availability component lead for next generation of data platform built on cloud-native Lakehouse architecture ‚òÅÔ∏è",
      "technologies": ["Java", "Python", "AWS"],
      "side": "right"
    },
    {
      "id": "2022",
      "title": "Vice President Software Engineer/Tech Lead",
      "company": "Goldman Sachs",
      "period": "2022 - 2023",
      "isCurrent": false,
      "description": "Data Lake Engineering - tech lead for firmwide Data Lake platform ingest services ‚öôÔ∏è",
      "technologies": ["Java", "Python", "Hadoop", "Flink"],
      "side": "left"
    },    
    {
      "id": "2019",
      "title": "Associate Software Engineer",
      "company": "Goldman Sachs",
      "period": "2019 - 2021",
      "isCurrent": false,
      "description": "Data Lake Engineering - contributed to enterprise Data Lake platform ingest & catalog services. Migrated ingest framework from MapReduce to Apache Flink üêøÔ∏è",
      "technologies": ["Java", "Hadoop", "Flink"],
      "side": "right"
    },
    {
      "id": "2016",
      "title": "Analyst Software Engineer",
      "company": "Goldman Sachs",
      "period": "2016 - 2019",
      "isCurrent": false,
      "description": "Data Lake Engineering - contributed to frontend + core backend metadata services for data cataloging, governance, and refinement for early stage enterprise Data Lake platform ‚öôÔ∏è",
      "technologies": ["Java, TypeScript", "JavaScript", "Node"],
      "side": "left"
    }
  ],
  "projects": [
    {
      "id": "corgimq",
      "title": "CorgiMQ",
      "description": "An open source lightweight Java message queue library built on your RDBMS.",
      "image": "/placeholder.svg?height=200&width=400",
      "technologies": ["Java", "Postgres", "JDBC", "RDBMS"],
      "githubUrl": "https://github.com/hailuand/corgimq",
      "liveUrl": "",
      "color": "primary"
    },
    {
      "id": "avro",
      "title": "Apache Avro",
      "description": "Apache Avro  data serialization system.",
      "image": "/placeholder.svg?height=200&width=400",
      "technologies": ["Open Source", "Data Format", "Serialization"],
      "githubUrl": "https://github.com/apache/avro",
      "liveUrl": "",
      "color": "secondary"
    },
    {
      "id": "parquet",
      "title": "Apache Parquet",
      "description": "Apache Parquet is a column-oriented data file format designed for efficient data storage and retrieval.",
      "image": "/placeholder.svg?height=200&width=400",
      "technologies": ["Open Source", "Data Format", "Serialization"],
      "githubUrl": "https://github.com/apache/parquet-java",
      "liveUrl": "",
      "color": "accent"
    }
  ],
  "talks": [
    {
      "id": "flink-forwad-22",
      "title": "Batch Processing at Scale with Flink & Iceberg",
      "event": "Flink Forward San Francisco",
      "date": "August 2022",
      "link": "https://www.flink-forward.org/san-francisco-2022/agenda#batch-processing-at-scale-with-flink---iceberg",
      "description": "How Goldman Sachs uses Flink and Iceberg to efficiently ingest, process, and manage massive data batches in the cloud."
    }
  ],
  "contact": {
    "email": "andreashailu@gmail.com",
    "linkedin": {
      "url": "https://linkedin.com/in/andreashailu",
      "display": "linkedin.com/in/andreashailu"
    },
    "github": {
      "url": "https://github.com",
      "display": "github.com/hailuand"
    },
    "twitter": {
      "url": "https://twitter.com",
      "display": "@johndoe"
    }
  },
  "social": {
    "github": "https://github.com/hailuand",
    "linkedin": "https://linkedin.com/in/andreashailu"
  }
}
